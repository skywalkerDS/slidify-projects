---
title: "Machine Learning: Predict the Manner of Exercise"
author: "Randy Qin"
date: "Wednesday, November 19, 2014"
output: html_document
---

### Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to quantify not only how much of a particular activity wearers do, but how well they do it. Our goal here will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants who were asked to perform barbell lifts correctly and incorrectly in 5 different ways, to predict the manner in which people did the exercise. 

Details are here: <http://groupware.les.inf.puc-rio.br/har>.

### Source Data 


The training data for this project are available here: 

<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>

The test data are available here: 

<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>

We would like to thank Groupware HAR for the generous offer allowing their data to be used for this study. 

### Data Exploration

As defined, data reflects 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

```{r}
pml_data <- read.csv("pml-training.csv", na="", as.is=T)
dim(pml_data)
```

This is a fairly large dataset, with 160 attributes.  Since we are interested in measurements from sensors, we want to drop the non-numeric data columns, clean out <NA>s, and make the categoy varible 'classe' as the predictor.

```{r}
# catch the result classes
classe <- pml_data[,ncol(pml_data)]
# drop any non-numeric columns
col_nums <- sapply(pml_data, is.numeric)
pml <- pml_data[,col_nums]
# only keep the measures
pml <- pml[,-c(1:4)]
# keep the columns, then add in predictor classe 
col_ds <- colnames(pml)
pml <- cbind(pml, classe)
colnames(pml)
summary(pml$classe)
```

### Build the model

All models start with traning and test sets preparation.  Considering the large size of dataset, the typical 70:30 split for training and test sets will produce a large training set.  We start with a training set with low thousands of records, a 15:85 split.

```{r, message=FALSE}
library(caret)

set.seed(331)
inTrain <- createDataPartition(y=pml$classe, p=0.15, list=F)
training <- pml[inTrain,]
testing <- pml[-inTrain,]
```
```{r}
dim(training);dim(testing)
```

This ~3000 training set is used for benchmarking the models below.

#### Cross validation and sample error

CART model: The default 25-reps Bootstrapping for training vs 10-fold cross validation repeating 3 times: 

```{r}
library(rpart)
tree <- train(classe ~ ., data=training, method='rpart')

cvCtrl <- trainControl(method="repeatedcv", repeats=3)
tree2 <- train(classe ~ ., data=training, method='rpart', tuneLength=30, trControl=cvCtrl)
```

To save space here, the tree results are not included but can be reproduced easily.  The 10 fold cross-validation training takes longer than bootstrap, for about 30 seconds, but the accuracy increased from bootstrap's 45% to 81%. 

#### The choices of model

Besides CART, we use multiple popular predication models and the results of accuray and performance are listed here:  

```{r, eval=FALSE}
# LDA
fit_lda <- train(classe ~ . , method='lda', data=training)
# Naive Bayes
library(klaR)
fit_nb <- train(classe ~ . , method='nb', data=training)
# Boosting
library(gbm)
fit_bt <- train(classe ~ . , method='gbm', data=training, verbose=F)
```

As a summary:

+ LDA is fast, accuracy is 70% in 8 seconds;
+ Naive Bayes has very similar accuracy as LDA, 71%, but it takes 830 seconds(!!!);
+ GBM is really good, accuracy 94%, training takes 360 seconds; and
+ CART accuracy 81% (10-fold, 3 reps), training takes 30 seconds

Before we choose GBM as our pick of model, let us check out the random forest:

```{r, message=FALSE}
library(randomForest)
rf_tree <- randomForest(classe ~ . , data=training, prox=T)
```
```{r}
rf_tree
```

Very impressive! 96% accuracy in 24 seconds of training, we have our winner model, Random Forest.

### Prediction

With the 96% accuracy, there is no meed to increase the size of trainging set.   We can start the prediction now.  

Remember the original dataset? It was transformed when we chose data fields for modeling.  For the real prediction, the test data must be in the same format as the training and testing sets, so We take advantage of the column list we kept to pick the columns from the real test data:

```{r}
pml_real <- read.csv("pml-testing.csv")
pml_cases <- subset(pml_real, select=col_ds)
pml_pred <- predict(rf_tree, pml_cases)
# we hide the result here
#pml_pred
```

### Conclusion

For categorized data such as exercise patterns, random forest and boosted tree are the choices of model for prediction, particularly random forest.  With just a smaller training set (and fast training), random forest can predict manner of exercise with 96% accuracy.

```{r, results='hide', echo=FALSE, eval=FALSE}
### Appendix: Project submission
answers = as.character(pml_pred)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)

```